{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80b2ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from itertools  import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel,delayed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from warnings import catch_warnings,filterwarnings   # catch_warnings暂时禁止警告，filterwarnings在警告过滤器中插入一条数据项。默认情况下，该数据项将被插到前面；\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5311d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#传入数据和参数，输出模型预测\n",
    "def model_forecast(history,config):\n",
    "    order, sorder, trend = config\n",
    "    model = SARIMAX(history,order=order,seasonal_order=sorder,trend=trend,enforce_stationarity=False, enforce_invertibility=False)\n",
    "    model_fit = model.fit(disp=False)   # disp如果为True则会打印收敛信息\n",
    "    # statsmodels.tsa.statespace.sarimax.SARIMAX.fit\n",
    "    yhat = model_fit.predict(len(history), len(history))   # 获取样本内拟合值的最后一个值\n",
    "    # statsmodels.tsa.statespace.sarimax.SARIMAXResults.predict\n",
    "    # 模型结果有四个方法获取值，predict、get_predict、forecast、get_forecast\n",
    "    # predict(start,end)、get_predict：样本内预测值，拟合值； 其中的参数start和end的意思是：获取拟合值的范围，默认是获取所有拟合值；当然也可以通过设置end来获取样本外预测值\n",
    "    # forecast(step)、get_forecast：样本外预测值，拟合值； 其中step为预测的周期数，如step=2，则得到接下来两个周期的预测值\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9c0b87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型评估指标,mape\n",
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100    \n",
    "\n",
    "#划分训练集和测试集\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a3984a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-step滚动向前预测\n",
    "def forward_valid(data, n_test, cfg):\n",
    "    predictions = list()   # 得到空列表\n",
    "    # 调用数据集划分函数train_test_split\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    history = [x for x in train]\n",
    "    for i in range(len(test)):\n",
    "        # 调用预测函数model_forecast\n",
    "        yhat = model_forecast(history, cfg)\n",
    "        # 接收预测结果\n",
    "        predictions.append(yhat)\n",
    "        # 用测试数据不断扩充训练数据（这里为什么不用预测数据扩充）\n",
    "        history.append(test[i])\n",
    "    # 调用评估函数mape，看效果\n",
    "    error = mape(test, predictions)\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a1c53fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型评估\n",
    "def score_model(data,n_test,cfg,debug=False):\n",
    "    result = None\n",
    "    key = str(cfg)\n",
    "    if debug:\n",
    "        # 调用滚动预测函数forward_valid\n",
    "        result = forward_valid(data, n_test, cfg)\n",
    "    else:\n",
    "        try:\n",
    "            # catch_warnings暂时禁止警告，filterwarnings在警告过滤器中插入一条数据项。默认情况下，该数据项将被插到前面；\n",
    "            with catch_warnings():\n",
    "                filterwarnings(\"ignore\")\n",
    "                # 调用滚动预测函数forward_valid\n",
    "                result = forward_valid(data, n_test, cfg)\n",
    "        except:\n",
    "            error = None\n",
    "            \n",
    "    return (key, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5eb52579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#网格搜索\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "    # parallel=True这个参数的意义是：由用户选择是否启用多进程。\n",
    "    scores = None\n",
    "    if parallel:\n",
    "        # 使用计算机全部的cpu核数多进程并行\n",
    "        # Joblib提供了一个简单的帮助类来编写并行化的循环。其核心思想是把代码写成生成器表达式的样子，然会再将它转换为并行计算\n",
    "        executor = Parallel(n_jobs=4, backend='multiprocessing')   # 使用所有cpu创建进程池\n",
    "        # 调用score_model函数，将参数列表中的参数循环，然后与数据一起调用函数\n",
    "        tasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)   # 调用score_model函数，并传参(data, n_test, cfg)\n",
    "        # 启动多进程\n",
    "        scores = executor(tasks)\n",
    "        ## Parallel(n_jobs=-1)(delayed(score_model)(data, n_test, cfg) for cfg in cfg_list) 也可以一步到位\n",
    "        \n",
    "    else:\n",
    "        scores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "    scores = [r for r in scores if r[1] != None]\n",
    "    scores.sort(key=lambda x: x[1])   # sort和lambda的联合使用，scores现在是列表，列表内是多个元组，这里针对元组的第二个值进行升序排序\n",
    "    return scores\n",
    "\n",
    "#生成参数列表\n",
    "def sarima_configs(seasonal=[0]):   \n",
    "    p = d = q = [0,1,2]\n",
    "    # product(A,B)函数,返回A和B中的元素组成的笛卡尔积的元组,\n",
    "    pdq = list(product(p, d, q))   \n",
    "    s = 32\n",
    "    seasonal_pdq = [(x[0], x[1], x[2], s) for x in list(product(p, d, q))]\n",
    "    t=['n','c','t','ct']\n",
    "    return list(product(pdq,seasonal_pdq,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46d216d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型训练\n",
    "def train_model(sale_df):\n",
    "    n_test = 3\n",
    "    p_b,d_b,q_b=[],[],[]\n",
    "    P_b,D_b,Q_b=[],[],[]\n",
    "    m_b,t_b=[],[]\n",
    "    model_id,error=[],[]\n",
    "    for i in sale_df['store_code'].unique():\n",
    "        data=sale_df[sale_df['store_code']==i]['y']\n",
    "        data=[i for i in data]\n",
    "        # 调用sarima_configs函数————> 返回多个参数多个值的组合列表\n",
    "        cfg_list = sarima_configs()\n",
    "        # 调用grid_search函数————> 返回一个列表，列表内是多个元组，元组第一个值是参数组合，第二个值是参数的mape得分，根据得分进行了升序排序，\n",
    "        scores = grid_search(data,cfg_list,n_test,parallel=True)\n",
    "        # 解析出每个分店的最优参数组合，并放入Dataframe中进行返回\n",
    "        p_b.append(int(scores[0][0][2]))\n",
    "        d_b.append(int(scores[0][0][5]))\n",
    "        q_b.append(int(scores[0][0][8]))\n",
    "        P_b.append(int(scores[0][0][13]))\n",
    "        D_b.append(int(scores[0][0][16]))\n",
    "        Q_b.append(int(scores[0][0][19]))\n",
    "        m_b.append(int(scores[0][0][22]))\n",
    "        t_b.append(str(scores[0][0][27]))\n",
    "        model_id.append(i)\n",
    "        error.append(scores[1][-1])\n",
    "        params_df=pd.DataFrame({'store_code': model_id, 'map': error,'p':p_b,'d':d_b,'q':q_b,'P':P_b,'D':D_b,'Q':Q_b,'m':m_b,'t':t_b})\n",
    "    return params_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ca44620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义预测函数，传入数据和参数，返回预测值\n",
    "def one_step_forecast(data,order,seasonal_order,t,h_fore):\n",
    "    predictions=list()\n",
    "    data=[i for i in data]\n",
    "    for i in range(h_fore):\n",
    "        model = SARIMAX(data, order=order, seasonal_order=seasonal_order,trend=t,enforce_stationarity=False, enforce_invertibility=False)\n",
    "        model_fit = model.fit(disp=False)\n",
    "        yhat = model_fit.predict(len(data), len(data))\n",
    "        data.append(yhat[0])\n",
    "        predictions.append(yhat[0])\n",
    "    return predictions\n",
    "\n",
    "\n",
    "#用for循环，多个序列预测\n",
    "def forecast_model(sale_df,params_df):\n",
    "    h_fore=4   # 预测的步数，将会用来作为循环次数，每次循环都把预测的最近的一步作为训练数据的追加数据\n",
    "    fore_list=[]\n",
    "    model_id=[]\n",
    "    for i in sale_df['store_code'].unique():\n",
    "        #params_list=params_df[params_df['store_code']==i]\n",
    "        # 读取每个分店的最优参数\n",
    "        data=sale_df[sale_df['store_code']==i]['y']\n",
    "        p=params_df[params_df['store_code']==i].iloc[:,2].values[0]\n",
    "        d=params_df[params_df['store_code']==i].iloc[:,3].values[0]\n",
    "        q=params_df[params_df['store_code']==i].iloc[:,4].values[0]\n",
    "        P=params_df[params_df['store_code']==i].iloc[:,5].values[0]\n",
    "        D=params_df[params_df['store_code']==i].iloc[:,6].values[0]\n",
    "        Q=params_df[params_df['store_code']==i].iloc[:,7].values[0]\n",
    "        m=params_df[params_df['store_code']==i].iloc[:,8].values[0]\n",
    "        t=params_df[params_df['store_code']==i].iloc[:,9].values[0]\n",
    "        order=(p, d, q)\n",
    "        seasonal_order=(P,D,Q,m)\n",
    "        # 调用one_step_forecast函数————> 拟合h_fore次数，返回4次拟合的结果列表\n",
    "        all_fore=one_step_forecast(data,order,seasonal_order,t,h_fore)\n",
    "        fore_list.append(all_fore)\n",
    "        \n",
    "        #以下为，多步预测，如果不使用滚动预测，则不调one_step_forecast函数\n",
    "        #model=SARIMAX(data, order=order,seasonal_order=seasonal_order,trend=t,enforce_stationarity=False,\n",
    "        #                                                enforce_invertibility=False)\n",
    "        #forecast_=model.fit(disp=-1).forecast(steps=h_fore)\n",
    "        #fore_list_flatten = [x for x in forecast_]\n",
    "        #fore_list.append(fore_list_flatten)\n",
    "        model_id.append(i)\n",
    "    df_forecast = pd.DataFrame({'store_code': model_id, 'fore': fore_list})\n",
    "    return df_forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1dad736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretreatment(all_data):\n",
    "    all_data = all_data[~(all_data['numbers']==1)]\n",
    "    all_data['year'] = all_data['date'].map(lambda x: x.split('-')[0])\n",
    "    all_data['mon_day'] = all_data['date'].map(lambda x: x[5:])\n",
    "\n",
    "    everYear_min_date, everYear_max_date = [], []\n",
    "    for k in all_data['year'].unique():\n",
    "        i_data = all_data[all_data['year']==k]\n",
    "        everYear_min_date.append(min(i_data['mon_day']))\n",
    "        everYear_max_date.append(max(i_data['mon_day']))\n",
    "\n",
    "    all_data = all_data[(all_data['mon_day']>=max(everYear_min_date)) & (all_data['mon_day']<=min(everYear_max_date))]\n",
    "    all_data.set_index('date',inplace=True)\n",
    "\n",
    "    all_data.rename({'numbers': 'y'},axis='columns',inplace=True)\n",
    "    all_data.insert(all_data.shape[1], 'store_code', 1)\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b4959",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_time=time.time()\n",
    "    all_data = pd.read_csv('./num_predict.csv')\n",
    "    all_data = pretreatment(all_data)\n",
    "    # sale_df=pd.read_excel('/home/test01/store_forecast/sale_df.xlsx')\n",
    "    # 调用train_model函数————> 返回最优参数组合\n",
    "    params_df=train_model(all_data)\n",
    "    # 调用forecast_model函数————> 返回每个分店对应的4个预测值（样本内的拟合值）\n",
    "    forecast_out=forecast_model(all_data,params_df)\n",
    "    end_time=time.time()\n",
    "    use_time=(end_time-start_time)//60\n",
    "    print('finish the process use',use_time,'mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82cd27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7fd453",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
