{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80b2ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from itertools  import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel,delayed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from warnings import catch_warnings,filterwarnings   # catch_warnings暂时禁止警告，filterwarnings在警告过滤器中插入一条数据项。默认情况下，该数据项将被插到前面；\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5311d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#传入数据和参数，输出模型预测\n",
    "def model_forecast(history,config):\n",
    "    order, sorder, trend = config\n",
    "    model = SARIMAX(history,order=order,seasonal_order=sorder,trend=trend,enforce_stationarity=False, enforce_invertibility=False)\n",
    "    model_fit = model.fit(disp=False)   # disp如果为True则会打印收敛信息\n",
    "    # statsmodels.tsa.statespace.sarimax.SARIMAX.fit\n",
    "    yhat = model_fit.predict(len(history), len(history))   # 获取样本内拟合值的最后一个值\n",
    "    # statsmodels.tsa.statespace.sarimax.SARIMAXResults.predict\n",
    "    # 模型结果有四个方法获取值，predict、get_predict、forecast、get_forecast\n",
    "    # predict(start,end)、get_predict：样本内预测值，拟合值； 其中的参数start和end的意思是：获取拟合值的范围，默认是获取所有拟合值；当然也可以通过设置end来获取样本外预测值\n",
    "    # forecast(step)、get_forecast：样本外预测值，拟合值； 其中step为预测的周期数，如step=2，则得到接下来两个周期的预测值\n",
    "    return yhat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9c0b87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型评估指标,mape\n",
    "def mape(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100    \n",
    "\n",
    "#划分训练集和测试集\n",
    "def train_test_split(data, n_test):\n",
    "    return data[:-n_test], data[-n_test:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a3984a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-step滚动向前预测\n",
    "def forward_valid(data, n_test, cfg):\n",
    "    predictions = list()   # 得到空列表\n",
    "    # 调用数据集划分函数train_test_split\n",
    "    train, test = train_test_split(data, n_test)\n",
    "    history = [x for x in train]\n",
    "    for i in range(len(test)):\n",
    "        # 调用预测函数model_forecast\n",
    "        yhat = model_forecast(history, cfg)\n",
    "        # 接收预测结果\n",
    "        predictions.append(yhat)\n",
    "        # 用测试数据不断扩充训练数据（这里为什么不用预测数据扩充）\n",
    "        history.append(test[i])\n",
    "    # 调用评估函数mape，看效果\n",
    "    error = mape(test, predictions)\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a1c53fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型评估\n",
    "def score_model(data,n_test,cfg,debug=False):\n",
    "    result = None\n",
    "    key = str(cfg)\n",
    "    if debug:\n",
    "        # 调用滚动预测函数forward_valid\n",
    "        result = forward_valid(data, n_test, cfg)\n",
    "    else:\n",
    "        try:\n",
    "            # catch_warnings暂时禁止警告，filterwarnings在警告过滤器中插入一条数据项。默认情况下，该数据项将被插到前面；\n",
    "            with catch_warnings():\n",
    "                filterwarnings(\"ignore\")\n",
    "                # 调用滚动预测函数forward_valid\n",
    "                result = forward_valid(data, n_test, cfg)\n",
    "        except:\n",
    "            error = None\n",
    "            \n",
    "    return (key, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5eb52579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#网格搜索\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "    # parallel=True这个参数的意义是：由用户选择是否启用多进程。\n",
    "    scores = None\n",
    "    if parallel:\n",
    "        # 使用计算机全部的cpu核数多进程并行\n",
    "        # Joblib提供了一个简单的帮助类来编写并行化的循环。其核心思想是把代码写成生成器表达式的样子，然会再将它转换为并行计算\n",
    "        executor = Parallel(n_jobs=4, backend='multiprocessing')   # 使用所有cpu创建进程池\n",
    "        # 调用score_model函数，将参数列表中的参数循环，然后与数据一起调用函数\n",
    "        tasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)   # 调用score_model函数，并传参(data, n_test, cfg)\n",
    "        # 启动多进程\n",
    "        scores = executor(tasks)\n",
    "        ## Parallel(n_jobs=-1)(delayed(score_model)(data, n_test, cfg) for cfg in cfg_list) 也可以一步到位\n",
    "        \n",
    "    else:\n",
    "        scores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "    scores = [r for r in scores if r[1] != None]\n",
    "    scores.sort(key=lambda x: x[1])   # sort和lambda的联合使用，scores现在是列表，列表内是多个元组，这里针对元组的第二个值进行升序排序\n",
    "    return scores\n",
    "\n",
    "#生成参数列表\n",
    "def sarima_configs(seasonal=[0]):   \n",
    "    p = d = q = [0,1,2]\n",
    "    # product(A,B)函数,返回A和B中的元素组成的笛卡尔积的元组,\n",
    "    pdq = list(product(p, d, q))   \n",
    "    s = 32\n",
    "    seasonal_pdq = [(x[0], x[1], x[2], s) for x in list(product(p, d, q))]\n",
    "    t=['n','c','t','ct']\n",
    "    return list(product(pdq,seasonal_pdq,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46d216d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型训练\n",
    "def train_model(sale_df):\n",
    "    n_test = 3\n",
    "    p_b,d_b,q_b=[],[],[]\n",
    "    P_b,D_b,Q_b=[],[],[]\n",
    "    m_b,t_b=[],[]\n",
    "    model_id,error=[],[]\n",
    "    for i in sale_df['store_code'].unique():\n",
    "        data=sale_df[sale_df['store_code']==i]['y']\n",
    "        data=[i for i in data]\n",
    "        # 调用sarima_configs函数————> 返回多个参数多个值的组合列表\n",
    "        cfg_list = sarima_configs()\n",
    "        # 调用grid_search函数————> 返回一个列表，列表内是多个元组，元组第一个值是参数组合，第二个值是参数的mape得分，根据得分进行了升序排序，\n",
    "        scores = grid_search(data,cfg_list,n_test,parallel=True)\n",
    "        # 解析出每个分店的最优参数组合，并放入Dataframe中进行返回\n",
    "        p_b.append(int(scores[0][0][2]))\n",
    "        d_b.append(int(scores[0][0][5]))\n",
    "        q_b.append(int(scores[0][0][8]))\n",
    "        P_b.append(int(scores[0][0][13]))\n",
    "        D_b.append(int(scores[0][0][16]))\n",
    "        Q_b.append(int(scores[0][0][19]))\n",
    "        m_b.append(int(scores[0][0][22]))\n",
    "        t_b.append(str(scores[0][0][27]))\n",
    "        model_id.append(i)\n",
    "        error.append(scores[1][-1])\n",
    "        params_df=pd.DataFrame({'store_code': model_id, 'map': error,'p':p_b,'d':d_b,'q':q_b,'P':P_b,'D':D_b,'Q':Q_b,'m':m_b,'t':t_b})\n",
    "    return params_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ca44620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义预测函数，传入数据和参数，返回预测值\n",
    "def one_step_forecast(data,order,seasonal_order,t,h_fore):\n",
    "    predictions=list()\n",
    "    data=[i for i in data]\n",
    "    for i in range(h_fore):\n",
    "        model = SARIMAX(data, order=order, seasonal_order=seasonal_order,trend=t,enforce_stationarity=False, enforce_invertibility=False)\n",
    "        model_fit = model.fit(disp=False)\n",
    "        yhat = model_fit.predict(len(data), len(data))\n",
    "        data.append(yhat[0])\n",
    "        predictions.append(yhat[0])\n",
    "    return predictions\n",
    "\n",
    "\n",
    "#用for循环，多个序列预测\n",
    "def forecast_model(sale_df,params_df):\n",
    "    h_fore=4   # 预测的步数，将会用来作为循环次数，每次循环都把预测的最近的一步作为训练数据的追加数据\n",
    "    fore_list=[]\n",
    "    model_id=[]\n",
    "    for i in sale_df['store_code'].unique():\n",
    "        #params_list=params_df[params_df['store_code']==i]\n",
    "        # 读取每个分店的最优参数\n",
    "        data=sale_df[sale_df['store_code']==i]['y']\n",
    "        p=params_df[params_df['store_code']==i].iloc[:,2].values[0]\n",
    "        d=params_df[params_df['store_code']==i].iloc[:,3].values[0]\n",
    "        q=params_df[params_df['store_code']==i].iloc[:,4].values[0]\n",
    "        P=params_df[params_df['store_code']==i].iloc[:,5].values[0]\n",
    "        D=params_df[params_df['store_code']==i].iloc[:,6].values[0]\n",
    "        Q=params_df[params_df['store_code']==i].iloc[:,7].values[0]\n",
    "        m=params_df[params_df['store_code']==i].iloc[:,8].values[0]\n",
    "        t=params_df[params_df['store_code']==i].iloc[:,9].values[0]\n",
    "        order=(p, d, q)\n",
    "        seasonal_order=(P,D,Q,m)\n",
    "        # 调用one_step_forecast函数————> 拟合h_fore次数，返回4次拟合的结果列表\n",
    "        all_fore=one_step_forecast(data,order,seasonal_order,t,h_fore)\n",
    "        fore_list.append(all_fore)\n",
    "        \n",
    "        #以下为，多步预测，如果不使用滚动预测，则不调one_step_forecast函数\n",
    "        #model=SARIMAX(data, order=order,seasonal_order=seasonal_order,trend=t,enforce_stationarity=False,\n",
    "        #                                                enforce_invertibility=False)\n",
    "        #forecast_=model.fit(disp=-1).forecast(steps=h_fore)\n",
    "        #fore_list_flatten = [x for x in forecast_]\n",
    "        #fore_list.append(fore_list_flatten)\n",
    "        model_id.append(i)\n",
    "    df_forecast = pd.DataFrame({'store_code': model_id, 'fore': fore_list})\n",
    "    return df_forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1dad736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretreatment(all_data):\n",
    "    all_data = all_data[~(all_data['numbers']==1)]\n",
    "    all_data['year'] = all_data['date'].map(lambda x: x.split('-')[0])\n",
    "    all_data['mon_day'] = all_data['date'].map(lambda x: x[5:])\n",
    "\n",
    "    everYear_min_date, everYear_max_date = [], []\n",
    "    for k in all_data['year'].unique():\n",
    "        i_data = all_data[all_data['year']==k]\n",
    "        everYear_min_date.append(min(i_data['mon_day']))\n",
    "        everYear_max_date.append(max(i_data['mon_day']))\n",
    "\n",
    "    all_data = all_data[(all_data['mon_day']>=max(everYear_min_date)) & (all_data['mon_day']<=min(everYear_max_date))]\n",
    "    all_data.set_index('date',inplace=True)\n",
    "\n",
    "    all_data.rename({'numbers': 'y'},axis='columns',inplace=True)\n",
    "    all_data.insert(all_data.shape[1], 'store_code', 1)\n",
    "    \n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "173b4959",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-34:\n",
      "Process SpawnPoolWorker-32:\n",
      "Process SpawnPoolWorker-33:\n",
      "Process SpawnPoolWorker-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/site-packages/joblib/pool.py\", line 147, in get\n",
      "    return recv()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 256, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "AttributeError: Can't get attribute 'score_model' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/site-packages/joblib/pool.py\", line 147, in get\n",
      "    return recv()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 256, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "AttributeError: Can't get attribute 'score_model' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/site-packages/joblib/pool.py\", line 147, in get\n",
      "    return recv()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 256, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "AttributeError: Can't get attribute 'score_model' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/site-packages/joblib/pool.py\", line 147, in get\n",
      "    return recv()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 256, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "AttributeError: Can't get attribute 'score_model' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-35:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/site-packages/joblib/pool.py\", line 147, in get\n",
      "    return recv()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 256, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "AttributeError: Can't get attribute 'score_model' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-36:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/site-packages/joblib/pool.py\", line 147, in get\n",
      "    return recv()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 256, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "AttributeError: Can't get attribute 'score_model' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-37:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/site-packages/joblib/pool.py\", line 147, in get\n",
      "    return recv()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 256, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "AttributeError: Can't get attribute 'score_model' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-38:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/site-packages/joblib/pool.py\", line 147, in get\n",
      "    return recv()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 256, in recv\n",
      "    return _ForkingPickler.loads(buf.getbuffer())\n",
      "AttributeError: Can't get attribute 'score_model' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-42:\n",
      "Process SpawnPoolWorker-41:\n",
      "Process SpawnPoolWorker-40:\n",
      "Process SpawnPoolWorker-39:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/site-packages/joblib/pool.py\", line 145, in get\n",
      "    racquire()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/site-packages/joblib/pool.py\", line 145, in get\n",
      "    racquire()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/site-packages/joblib/pool.py\", line 145, in get\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/site-packages/joblib/pool.py\", line 147, in get\n",
      "    return recv()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 255, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/ayd/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bm/wl4738qx08b4r1vvn6jpygfh0000gn/T/ipykernel_41752/1610892455.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# sale_df=pd.read_excel('/home/test01/store_forecast/sale_df.xlsx')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# 调用train_model函数————> 返回最优参数组合\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mparams_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# 调用forecast_model函数————> 返回每个分店对应的4个预测值（样本内的拟合值）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mforecast_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforecast_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bm/wl4738qx08b4r1vvn6jpygfh0000gn/T/ipykernel_41752/67714610.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(sale_df)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mcfg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msarima_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# 调用grid_search函数————> 返回一个列表，列表内是多个元组，元组第一个值是参数组合，第二个值是参数的mape得分，根据得分进行了升序排序，\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# 解析出每个分店的最优参数组合，并放入Dataframe中进行返回\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mp_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bm/wl4738qx08b4r1vvn6jpygfh0000gn/T/ipykernel_41752/767353309.py\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(data, cfg_list, n_test, parallel)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcfg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcfg_list\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 调用score_model函数，并传参(data, n_test, cfg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# 启动多进程\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m## Parallel(n_jobs=-1)(delayed(score_model)(data, n_test, cfg) for cfg in cfg_list) 也可以一步到位\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    start_time=time.time()\n",
    "    all_data = pd.read_csv('./num_predict.csv')\n",
    "    all_data = pretreatment(all_data)\n",
    "    # sale_df=pd.read_excel('/home/test01/store_forecast/sale_df.xlsx')\n",
    "    # 调用train_model函数————> 返回最优参数组合\n",
    "    params_df=train_model(all_data)\n",
    "    # 调用forecast_model函数————> 返回每个分店对应的4个预测值（样本内的拟合值）\n",
    "    forecast_out=forecast_model(all_data,params_df)\n",
    "    end_time=time.time()\n",
    "    use_time=(end_time-start_time)//60\n",
    "    print('finish the process use',use_time,'mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82cd27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7fd453",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
